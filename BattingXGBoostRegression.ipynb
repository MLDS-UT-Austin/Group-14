{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, mean_absolute_error, precision_score, recall_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from itertools import product\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 2016-19 data\n",
    "data = pd.read_csv('data/batting_season_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "data[\"playerid\"] = label_encoder.fit_transform(data[\"Name\"])\n",
    "\n",
    "data['playerid'] = data['playerid'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Part 1: XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random state for reproducibility\n",
    "RANDOMSTATE=120\n",
    "\n",
    "# Define reproducible k-folds for cross-validation\n",
    "kfolds = KFold(n_splits=10, shuffle=True, random_state=RANDOMSTATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default hyperparameters\n",
    "param_dict = {'n_estimators':500, 'learning_rate':0.01, 'max_depth':5, 'subsample':0.4, 'colsample_bytree':0.3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning(xtrain, ytrain, name):\n",
    "    \"\"\"Function to build XGBoost models and tune hyperparameters in multiple steps.\"\"\"\n",
    "\n",
    "    # Reset default hyperparameters\n",
    "    param_dict = {'n_estimators':500, 'learning_rate':0.01, 'max_depth':5, 'subsample':0.4, 'colsample_bytree':0.3}\n",
    "    \n",
    "    # Define and train base model\n",
    "    base_model = xgb.XGBRegressor(eval_metric='rmse', **param_dict, verbosity=0)\n",
    "    print(base_model)\n",
    "    base_model.fit(xtrain, ytrain)\n",
    "    score = base_model.score(xtrain, ytrain)   \n",
    "    print(\"Training score: \", score) \n",
    "\n",
    "    # Cross-validatation \n",
    "    scores = -cross_val_score(base_model, xtrain, ytrain, cv=5, scoring='neg_mean_absolute_error')\n",
    "    print(\"Mean cross-validation score: %.2f\" % scores.mean())\n",
    "\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=RANDOMSTATE)\n",
    "    kf_cv_scores = -cross_val_score(base_model, xtrain, ytrain, cv=kfold, scoring='neg_mean_absolute_error')\n",
    "    print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())\n",
    "\n",
    "    # Predict test data with base model\n",
    "    base_ypred = base_model.predict(xtest)\n",
    "    base_mae = mean_absolute_error(ytest, base_ypred)\n",
    "    base_mse = mean_squared_error(ytest, base_ypred)\n",
    "    print(\"MAE: %.2f\" % base_mae)\n",
    "    print(\"MSE: %.2f\" % base_mse)\n",
    "    print(\"RMSE: %.2f\" % (base_mse**(1/2.0)))\n",
    "\n",
    "    # Plot model performance\n",
    "    x_ax = range(len(ytest))\n",
    "    plt.scatter(x_ax, ytest, s=5, color=\"blue\", label=\"actual\")\n",
    "    plt.plot(x_ax, base_ypred, lw=0.8, color=\"red\", label=\"predicted\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Display and save feature importance chart\n",
    "    xgb.plot_importance(base_model, max_num_features = 15)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('base_'+name+'_1619.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Display one decision tree\n",
    "    fig, ax = plt.subplots(figsize=(30, 30))\n",
    "    xgb.plot_tree(base_model, num_trees=20, rankdir='LR', ax=ax)\n",
    "    plt.show()\n",
    "\n",
    "    # Hyperparameter grid search step 1: max depth\n",
    "    model = xgb.XGBRegressor(eval_metric='rmse', **param_dict)\n",
    "    print(model)\n",
    "    max_depth = range(3, 9, 1)\n",
    "    param_grid = dict(max_depth=max_depth)\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=RANDOMSTATE)\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_absolute_error', n_jobs=-1, cv=kfold, verbose=1)\n",
    "    grid_result = grid_search.fit(xtrain, ytrain)\n",
    "    param_dict['max_depth'] = grid_result.best_params_['max_depth']\n",
    "    print(grid_result.best_score_, grid_result.best_params_)\n",
    "\n",
    "    # Hyperparameter grid search step 2: subsample, colsample_bytree\n",
    "    model2 = xgb.XGBRegressor(eval_metric='rmse', **param_dict)\n",
    "    print(model2)\n",
    "    subsample = np.linspace(0.4, 1.0, 7)\n",
    "    colsample_bytree = np.linspace(0.1, 0.35, 6)\n",
    "    param_grid = dict(subsample=subsample, colsample_bytree=colsample_bytree, max_depth=[grid_result.best_params_['max_depth']])\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=RANDOMSTATE)\n",
    "    grid_search = GridSearchCV(model2, param_grid, scoring='neg_mean_absolute_error', n_jobs=-1, cv=kfold, verbose=1)\n",
    "    grid_result = grid_search.fit(xtrain, ytrain)\n",
    "    param_dict['subsample'] = grid_result.best_params_['subsample']\n",
    "    param_dict['colsample_bytree'] = grid_result.best_params_['colsample_bytree']\n",
    "    print(grid_result.best_score_, grid_result.best_params_)\n",
    "\n",
    "    # Hyperparameter grid search step 3: learning rate\n",
    "    model3 = xgb.XGBRegressor(eval_metric='rmse', **param_dict)\n",
    "    print(model3)\n",
    "    learning_rate = [0.0001, 0.001, 0.01, 0.1]\n",
    "    param_grid = dict(learning_rate=learning_rate, subsample=[grid_result.best_params_['subsample']], \n",
    "                      colsample_bytree=[grid_result.best_params_['colsample_bytree']], \n",
    "                      max_depth=[grid_result.best_params_['max_depth']])\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=RANDOMSTATE)\n",
    "    grid_search = GridSearchCV(model3, param_grid, scoring='neg_mean_absolute_error', n_jobs=-1, cv=kfold, verbose=1)\n",
    "    grid_result = grid_search.fit(xtrain, ytrain)\n",
    "    param_dict['learning_rate'] = grid_result.best_params_['learning_rate']\n",
    "    print(grid_result.best_score_, grid_result.best_params_)\n",
    "\n",
    "    # Hyperparameter grid search step 4: number of estimators\n",
    "    model4 = xgb.XGBRegressor(eval_metric='rmse', **param_dict)\n",
    "    print(model4)\n",
    "    n_estimators = [100, 200, 300, 400, 500]\n",
    "    param_grid = dict(n_estimators=n_estimators, learning_rate=[grid_result.best_params_['learning_rate']], \n",
    "                      subsample=[grid_result.best_params_['subsample']], \n",
    "                      colsample_bytree=[grid_result.best_params_['colsample_bytree']], \n",
    "                      max_depth=[grid_result.best_params_['max_depth']])\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=RANDOMSTATE)\n",
    "    grid_search = GridSearchCV(model4, param_grid, scoring='neg_mean_absolute_error', n_jobs=-1, cv=kfold, verbose=1)\n",
    "    grid_result = grid_search.fit(xtrain, ytrain)\n",
    "    param_dict['n_estimators'] = grid_result.best_params_['n_estimators']\n",
    "    best_params_list.append(param_dict)\n",
    "    print(grid_result.best_score_, grid_result.best_params_)\n",
    "    \n",
    "    # Train best parameter model    \n",
    "    model5 = xgb.XGBRegressor(eval_metric='rmse', **param_dict)\n",
    "    model5.fit(xtrain, ytrain)\n",
    "\n",
    "    score = model5.score(xtrain, ytrain)   \n",
    "    print(\"Training score: \", score) \n",
    "\n",
    "    # Cross-validataion \n",
    "    scores = -cross_val_score(model5, xtrain, ytrain, cv=5, scoring='neg_mean_absolute_error')\n",
    "    print(\"Mean cross-validation score: %.2f\" % scores.mean())\n",
    "\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=RANDOMSTATE)\n",
    "    kf_cv_scores = -cross_val_score(model5, xtrain, ytrain, cv=kfold, scoring='neg_mean_absolute_error')\n",
    "    print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())\n",
    "\n",
    "    # Predict test set\n",
    "    ypred = model5.predict(xtest)\n",
    "    mae = mean_absolute_error(ytest, ypred)\n",
    "    mse = mean_squared_error(ytest, ypred)\n",
    "    print(\"MAE: %.2f\" % mae)\n",
    "    print(\"MSE: %.2f\" % mse)\n",
    "    print(\"RMSE: %.2f\" % (mse**(1/2.0)))\n",
    "\n",
    "    # Plot model performance\n",
    "    x_ax = range(len(ytest))\n",
    "    plt.scatter(x_ax, ytest, s=5, color=\"blue\", label=\"actual\")\n",
    "    plt.plot(x_ax, ypred, lw=0.8, color=\"red\", label=\"predicted\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Save model\n",
    "    joblib.dump(model5, name+\"_1619.joblib.dat\")\n",
    "    \n",
    "    # Display feature importance table\n",
    "    xgb.plot_importance(model5, max_num_features = 15)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(name+'_1619.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Display one decision tree\n",
    "    fig, ax = plt.subplots(figsize=(30, 30))\n",
    "    xgb.plot_tree(model5, num_trees=20, rankdir='LR', ax=ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = data.drop(['playerid', 'Name', \"3B\", \"AB\", \"BB\"], axis=1)\n",
    "y = data['H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all target variables\n",
    "yab = data['AB_Tgt']\n",
    "yhr = data['HR_Tgt']\n",
    "yrbi = data['RBI_Tgt']\n",
    "ysb = data['SB_Tgt']\n",
    "ycs = data['CS_Tgt']\n",
    "yavg = data['AVG_Tgt']\n",
    "yobp = data['OBP_Tgt']\n",
    "yops = data['OPS_Tgt']\n",
    "ydol = data['Dol_Tgt']\n",
    "\n",
    "# Define lists of target variables and names\n",
    "ys = [data['PA_Tgt'], data['AB_Tgt'], data['R_Tgt'], data['HR_Tgt'], data['RBI_Tgt'], data['SB_Tgt'], data['CS_Tgt'], data['AVG_Tgt'], data['OBP_Tgt'], data['OPS_Tgt'], data['Dol_Tgt']]\n",
    "names = ['ypa', 'yab', 'yr', 'yhr', 'yrbi', 'ysb', 'ycs', 'yavg', 'yobp', 'yops', 'ydol']\n",
    "stat_names = ['PA', 'AB', 'R', 'HR', 'RBI', 'SB', 'CS', 'AVG', 'OBP', 'OPS', 'Dol']\n",
    "baselines = [data['PA_Lag1'], data['AB_Lag1'], data['R_Lag1'], data['HR_Lag1'], data['RBI_Lag1'], data['SB_Lag1'], data['CS_Lag1'], data['AVG_Lag1'], data['OBP_Lag1'], data['OPS_Lag1'], data['Dol_Lag1']]\n",
    "models = []\n",
    "best_params_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tuning function for all target variables\n",
    "for i in range(len(ys)):\n",
    "    print(names[i],':')\n",
    "    y = ys[i]\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=RANDOMSTATE)\n",
    "    tuning(xtrain, ytrain, names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dictionary of best hyperparameters for all stats.\n",
    "dict(zip(stat_names,best_params_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_2016_19 = list(zip(names,best_params_list))\n",
    "params_2016_19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Part 2: XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 2016-19 dataset\n",
    "\n",
    "dfc = pd.read_csv('2016-19_batting.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set feature values to 2016-19 dataset.\n",
    "\n",
    "Xc = dfc.drop(['playerid', 'Name', 'Team', 'League', 'Team_Traded', 'League_Traded', 'Team_Lag1', \n",
    "          'League_Lag1', 'PA_Tgt', 'AB_Tgt', 'R_Tgt', 'HR_Tgt', 'RBI_Tgt', 'SB_Tgt', 'CS_Tgt', 'AVG_Tgt', 'OBP_Tgt', 'OPS_Tgt', \n",
    "            'Dol_Tgt', 'PA_Tgt_Cat', 'R_Tgt_Cat', 'HR_Tgt_Cat', 'RBI_Tgt_Cat', 'SB_Tgt_Cat', 'CS_Tgt_Cat', 'AVG_Tgt_Cat', \n",
    "            'OBP_Tgt_Cat', 'OPS_Tgt_Cat', 'Dol_Tgt_Cat', 'PA_Tgt_Code', 'R_Tgt_Code', 'HR_Tgt_Code', 'RBI_Tgt_Code', \n",
    "            'SB_Tgt_Code', 'CS_Tgt_Code', 'AVG_Tgt_Code', 'OBP_Tgt_Code', 'OPS_Tgt_Code', 'Dol_Tgt_Code', 'Season'\n",
    "            ], axis=1)\n",
    "\n",
    "yc = dfc['PA_Tgt_Code']\n",
    "\n",
    "# Define target values\n",
    "\n",
    "ypac = dfc['PA_Tgt_Code']\n",
    "yrc = dfc['R_Tgt_Code']\n",
    "yhrc = dfc['HR_Tgt_Code']\n",
    "yrbic = dfc['RBI_Tgt_Code']\n",
    "ysbc = dfc['SB_Tgt_Code']\n",
    "ycsc = dfc['CS_Tgt_Code']\n",
    "yavgc = dfc['AVG_Tgt_Code']\n",
    "yobpc = dfc['OBP_Tgt_Code']\n",
    "yopsc = dfc['OPS_Tgt_Code']\n",
    "ydolc = dfc['Dol_Tgt_Code']\n",
    "\n",
    "# Build lists of target variables and names\n",
    "ycs = [dfc['PA_Tgt_Code'], dfc['R_Tgt_Code'], dfc['HR_Tgt_Code'], dfc['RBI_Tgt_Code'], dfc['SB_Tgt_Code'], \n",
    "      dfc['CS_Tgt_Code'], dfc['AVG_Tgt_Code'], dfc['OBP_Tgt_Code'], dfc['OPS_Tgt_Code'], dfc['Dol_Tgt_Code']]\n",
    "names = ['ypac', 'yrc', 'yhrc', 'yrbic', 'ysbc', 'ycsc', 'yavgc', 'yobpc', 'yopsc', 'ydolc']\n",
    "\n",
    "# Define list of non-outlier labels for each statistic\n",
    "nonoutliers = [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_tuning(xtrain, ytrain, name, kfold, nonoutlier):\n",
    "    \"\"\"Function to build XGBoost classifier models and tune hyperparameters in multiple steps.\"\"\"\n",
    "\n",
    "    # Reset default hyperparameters\n",
    "    param_dict = {'n_estimators':500, 'learning_rate':0.01, 'max_depth':5, \n",
    "                  'subsample':0.5, 'colsample_bytree':0.3}\n",
    "    \n",
    "    # Define and train base model\n",
    "    base_model = xgb.XGBClassifier(eval_metric='merror', **param_dict, verbosity=0, use_label_encoder=False)\n",
    "    print(base_model)\n",
    "    base_model.fit(xtrain, ytrain)\n",
    "    score = base_model.score(xtrain, ytrain)   \n",
    "    print(\"Training score: \", score) \n",
    "\n",
    "    # Cross-validataion \n",
    "    \n",
    "    # Construct pipeline to run SMOTE oversampling for each fold of cross-validation\n",
    "    imb_pipeline = make_pipeline(SMOTE(random_state=RANDOMSTATE), \n",
    "                              xgb.XGBClassifier(eval_metric='merror', **param_dict, verbosity=0, use_label_encoder=False))\n",
    "    \n",
    "    scores = cross_val_score(imb_pipeline, xtrain, ytrain, scoring='f1_micro', cv=5)\n",
    "    print(\"Mean cross-validation score: %.2f\" % scores.mean())\n",
    "    kf_cv_scores = cross_val_score(imb_pipeline, xtrain, ytrain, scoring='f1_micro', cv=kfold)\n",
    "    print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())\n",
    "\n",
    "    # Predict test set using base model\n",
    "    base_ypred = base_model.predict(xtest)\n",
    "    base_precision = precision_score(ytest, base_ypred, average='weighted')\n",
    "    base_recall = recall_score(ytest, base_ypred, average='weighted')\n",
    "    print(\"Precision: %.2f%%\" % (base_precision * 100.0))\n",
    "    print(\"Recall: %.2f%%\" % (base_recall * 100.0))\n",
    "    \n",
    "    # Define outlier precision and recall measures to exclude non-outlier values\n",
    "    base_outlier_precision = precision_score(ytest[ytest!=nonoutlier], base_ypred[ytest!=nonoutlier], average='weighted')\n",
    "    base_outlier_recall = recall_score(ytest[ytest!=nonoutlier], base_ypred[ytest!=nonoutlier], average='weighted')\n",
    "    print(\"Outlier Precision: %.2f%%\" % (base_outlier_precision * 100.0))\n",
    "    print(\"Outlier Recall: %.2f%%\" % (base_outlier_recall * 100.0))\n",
    "    \n",
    "    # Plot model performance\n",
    "    x_ax = range(len(ytest))\n",
    "    plt.scatter(x_ax, ytest, s=5, color=\"blue\", label=\"actual\")\n",
    "    plt.plot(x_ax, base_ypred, lw=0.8, color=\"red\", label=\"predicted\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Display and save feature importance chart\n",
    "    xgb.plot_importance(base_model, max_num_features = 15)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('base_clf_'+name+'.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Hyperparameter grid search step 1: max depth\n",
    "    param_dict = {'xgbclassifier__n_estimators':500, 'xgbclassifier__learning_rate':0.01, 'xgbclassifier__max_depth':5, \n",
    "                  'xgbclassifier__subsample':0.1, 'xgbclassifier__colsample_bytree':0.3}\n",
    "    \n",
    "    model = make_pipeline(SMOTE(random_state=RANDOMSTATE), \n",
    "                           xgb.XGBClassifier(eval_metric='merror', **param_dict, verbosity=0, use_label_encoder=False))\n",
    "    print(model)\n",
    "    max_depth = range(3, 9, 1)\n",
    "    param_grid = dict(xgbclassifier__max_depth=max_depth)\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring='f1_micro', n_jobs=-1, cv=kfold, verbose=1)\n",
    "    grid_result = grid_search.fit(xtrain, ytrain)\n",
    "    param_dict['xgbclassifier__max_depth'] = grid_result.best_params_['xgbclassifier__max_depth']\n",
    "    print(grid_result.best_score_, grid_result.best_params_)\n",
    "\n",
    "    # Hyperparameter grid search step 2: subsample, colsample_bytree\n",
    "    model2 = make_pipeline(SMOTE(random_state=RANDOMSTATE), \n",
    "                           xgb.XGBClassifier(eval_metric='merror', **param_dict, verbosity=0, use_label_encoder=False))\n",
    "    print(model2)\n",
    "    subsample = np.linspace(0.4, 1, 7)\n",
    "    colsample_bytree = np.linspace(0.1, 0.35, 6)\n",
    "    param_grid = dict(xgbclassifier__subsample=subsample, xgbclassifier__colsample_bytree=colsample_bytree, \n",
    "                      xgbclassifier__max_depth=[grid_result.best_params_['xgbclassifier__max_depth']])\n",
    "    grid_search = GridSearchCV(model2, param_grid, scoring='f1_micro', n_jobs=-1, cv=kfold, return_train_score=True, verbose=1)\n",
    "    grid_result = grid_search.fit(xtrain, ytrain)\n",
    "    param_dict['xgbclassifier__subsample'] = grid_result.best_params_['xgbclassifier__subsample']\n",
    "    param_dict['xgbclassifier__colsample_bytree'] = grid_result.best_params_['xgbclassifier__colsample_bytree']\n",
    "    print(grid_result.best_score_, grid_result.best_params_)\n",
    "\n",
    "    # Hyperparameter grid search step 3: learning rate\n",
    "    model3 = make_pipeline(SMOTE(random_state=RANDOMSTATE), \n",
    "                           xgb.XGBClassifier(eval_metric='merror', **param_dict, verbosity=0, use_label_encoder=False))\n",
    "    print(model3)\n",
    "    learning_rate = [0.0001, 0.001, 0.01, 0.1]\n",
    "    param_grid = dict(xgbclassifier__learning_rate=learning_rate, \n",
    "                      xgbclassifier__subsample=[grid_result.best_params_['xgbclassifier__subsample']], \n",
    "                      xgbclassifier__colsample_bytree=[grid_result.best_params_['xgbclassifier__colsample_bytree']], \n",
    "                      xgbclassifier__max_depth=[grid_result.best_params_['xgbclassifier__max_depth']])\n",
    "    grid_search = GridSearchCV(model3, param_grid, scoring='f1_micro', n_jobs=-1, cv=kfold, return_train_score=True, verbose=1)\n",
    "    grid_result = grid_search.fit(xtrain, ytrain)\n",
    "    param_dict['xgbclassifier__learning_rate'] = grid_result.best_params_['xgbclassifier__learning_rate']\n",
    "    print(grid_result.best_score_, grid_result.best_params_)\n",
    "\n",
    "    # Hyperparameter grid search step 4: number of estimators\n",
    "    model4 = make_pipeline(SMOTE(random_state=RANDOMSTATE), \n",
    "                           xgb.XGBClassifier(eval_metric='merror', **param_dict, verbosity=0, use_label_encoder=False))\n",
    "    print(model4)\n",
    "    n_estimators = [100, 200, 300, 400, 500]\n",
    "    param_grid = dict(xgbclassifier__n_estimators=n_estimators, \n",
    "                      xgbclassifier__learning_rate=[grid_result.best_params_['xgbclassifier__learning_rate']], \n",
    "                      xgbclassifier__subsample=[grid_result.best_params_['xgbclassifier__subsample']], \n",
    "                      xgbclassifier__colsample_bytree=[grid_result.best_params_['xgbclassifier__colsample_bytree']], \n",
    "                      xgbclassifier__max_depth=[grid_result.best_params_['xgbclassifier__max_depth']])\n",
    "    grid_search = GridSearchCV(model4, param_grid, scoring='f1_micro', n_jobs=-1, cv=kfold, return_train_score=True, verbose=1)\n",
    "    grid_result = grid_search.fit(xtrain, ytrain)\n",
    "    param_dict['xgbclassifier__n_estimators'] = grid_result.best_params_['xgbclassifier__n_estimators']\n",
    "    best_params_list.append(param_dict)\n",
    "    print(grid_result.best_score_, grid_result.best_params_)\n",
    "    \n",
    "    # Train best parameter model\n",
    "    \n",
    "    model5 = make_pipeline(SMOTE(random_state=RANDOMSTATE), \n",
    "                           xgb.XGBClassifier(eval_metric='merror', **param_dict, verbosity=0, use_label_encoder=False))\n",
    "    \n",
    "    model5.fit(xtrain, ytrain)\n",
    "    score = model5.score(xtrain, ytrain)   \n",
    "    print(\"Training score: \", score) \n",
    "\n",
    "    # Cross-validataion \n",
    "    scores = cross_val_score(model5, xtrain, ytrain, cv=5, scoring='f1_micro')\n",
    "    print(\"Mean cross-validation score: %.2f\" % scores.mean())\n",
    "    kf_cv_scores = cross_val_score(model5, xtrain, ytrain, cv=kfold, scoring='f1_micro')\n",
    "    print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())\n",
    "\n",
    "    # Predict test set with best parameter model\n",
    "    ypred = model5.predict(xtest)\n",
    "    precision = precision_score(ytest, ypred, average='weighted')\n",
    "    recall = recall_score(ytest, ypred, average='weighted')\n",
    "    print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
    "    print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
    "    outlier_precision = precision_score(ytest[ytest!=nonoutlier], ypred[ytest!=nonoutlier], average='weighted')\n",
    "    outlier_recall = recall_score(ytest[ytest!=nonoutlier], ypred[ytest!=nonoutlier], average='weighted')\n",
    "    print(\"Outlier Precision: %.2f%%\" % (outlier_precision * 100.0))\n",
    "    print(\"Outlier Recall: %.2f%%\" % (outlier_recall * 100.0))\n",
    "\n",
    "    # Plot model performance\n",
    "    x_ax = range(len(ytest))\n",
    "    plt.scatter(x_ax, ytest, s=5, color=\"blue\", label=\"actual\")\n",
    "    plt.plot(x_ax, ypred, lw=0.8, color=\"red\", label=\"predicted\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Save model\n",
    "    joblib.dump(model5, name+\"_clf.joblib.dat\")\n",
    "    \n",
    "    # Display and save feature importance chart\n",
    "    xgb.plot_importance(model5[1], max_num_features = 15)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('best_clf_'+name+'.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Display one decision tree\n",
    "    fig, ax = plt.subplots(figsize=(30, 30))\n",
    "    xgb.plot_tree(model5[1], num_trees=20, rankdir='LR', ax=ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost classifier and tune hyperparemeters for each target variables\n",
    "RANDOMSTATE = 120\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=RANDOMSTATE)\n",
    "best_params_list = []\n",
    "\n",
    "for i in range(len(ycs)):\n",
    "    print(names[i],':')\n",
    "    y = ycs[i]\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(Xc, y, test_size=0.2, random_state=RANDOMSTATE)\n",
    "    clf_tuning(xtrain, ytrain, names[i], kfold, nonoutliers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 162-game scaled 2020 data: final prediction test set\n",
    "df20 = pd.read_csv('2020_batting_scaled.csv')\n",
    "\n",
    "dftest = df20.drop(['playerid', 'Name', 'Team', 'League', 'Team_Traded', 'League_Traded', 'Team_Lag1', \n",
    "          'League_Lag1', 'PA_Tgt', 'AB_Tgt', 'R_Tgt', 'HR_Tgt', 'RBI_Tgt', 'SB_Tgt', 'CS_Tgt', 'AVG_Tgt', 'OBP_Tgt', 'OPS_Tgt', \n",
    "            'Dol_Tgt', 'PA_Tgt_Cat', 'R_Tgt_Cat', 'HR_Tgt_Cat', 'RBI_Tgt_Cat', 'SB_Tgt_Cat', 'CS_Tgt_Cat', 'AVG_Tgt_Cat', \n",
    "            'OBP_Tgt_Cat', 'OPS_Tgt_Cat', 'Dol_Tgt_Cat', 'PA_Tgt_Code', 'R_Tgt_Code', 'HR_Tgt_Code', 'RBI_Tgt_Code', \n",
    "            'SB_Tgt_Code', 'CS_Tgt_Code', 'AVG_Tgt_Code', 'OBP_Tgt_Code', 'OPS_Tgt_Code', 'Dol_Tgt_Code', 'Season'\n",
    "            ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all models, predict 2021 values for all statistics\n",
    "\n",
    "pa_model = joblib.load('ypa_1619.joblib.dat')\n",
    "df20['PA_21'] = pa_model.predict(dftest)\n",
    "\n",
    "ab_model = joblib.load('yab_1619.joblib.dat')\n",
    "df20['AB_21'] = ab_model.predict(dftest)\n",
    "\n",
    "r_model = joblib.load('yr_1619.joblib.dat')\n",
    "df20['R_21'] = r_model.predict(dftest)\n",
    "\n",
    "hr_model = joblib.load('yhr_1619.joblib.dat')\n",
    "df20['HR_21'] = hr_model.predict(dftest)\n",
    "\n",
    "rbi_model = joblib.load('yrbi_1619.joblib.dat')\n",
    "df20['RBI_21'] = rbi_model.predict(dftest)\n",
    "\n",
    "sb_model = joblib.load('ysb_1619.joblib.dat')\n",
    "df20['SB_21'] = sb_model.predict(dftest)\n",
    "\n",
    "cs_model = joblib.load('ycs_1619.joblib.dat')\n",
    "df20['CS_21'] = cs_model.predict(dftest)\n",
    "\n",
    "avg_model = joblib.load('yavg_1619.joblib.dat')\n",
    "df20['AVG_21'] = avg_model.predict(dftest)\n",
    "\n",
    "obp_model = joblib.load('yobp_1619.joblib.dat')\n",
    "df20['OBP_21'] = obp_model.predict(dftest)\n",
    "\n",
    "ops_model = joblib.load('yops_1619.joblib.dat')\n",
    "df20['OPS_21'] = ops_model.predict(dftest)\n",
    "\n",
    "dol_model = joblib.load('ydol_1619.joblib.dat')\n",
    "df20['Dol_21'] = dol_model.predict(dftest)\n",
    "\n",
    "pa_cmodel = joblib.load('ypac_clf.joblib.dat')\n",
    "df20['PA_21_Tier'] = pa_cmodel.predict(dftest)\n",
    "\n",
    "r_cmodel = joblib.load('yrc_clf.joblib.dat')\n",
    "df20['R_21_Tier'] = r_cmodel.predict(dftest)\n",
    "\n",
    "hr_cmodel = joblib.load('yhrc_clf.joblib.dat')\n",
    "df20['HR_21_Tier'] = hr_cmodel.predict(dftest)\n",
    "\n",
    "rbi_cmodel = joblib.load('yrbic_clf.joblib.dat')\n",
    "df20['RBI_21_Tier'] = rbi_cmodel.predict(dftest)\n",
    "\n",
    "sb_cmodel = joblib.load('ysbc_clf.joblib.dat')\n",
    "df20['SB_21_Tier'] = sb_cmodel.predict(dftest)\n",
    "\n",
    "cs_cmodel = joblib.load('ycsc_clf.joblib.dat')\n",
    "df20['CS_21_Tier'] = cs_cmodel.predict(dftest)\n",
    "\n",
    "avg_cmodel = joblib.load('yavgc_clf.joblib.dat')\n",
    "df20['AVG_21_Tier'] = avg_cmodel.predict(dftest)\n",
    "\n",
    "obp_cmodel = joblib.load('yobpc_clf.joblib.dat')\n",
    "df20['OBP_21_Tier'] = obp_cmodel.predict(dftest)\n",
    "\n",
    "ops_cmodel = joblib.load('yopsc_clf.joblib.dat')\n",
    "df20['OPS_21_Tier'] = ops_cmodel.predict(dftest)\n",
    "\n",
    "dol_cmodel = joblib.load('ydolc_clf.joblib.dat')\n",
    "df20['Dol_21_Tier'] = dol_cmodel.predict(dftest)\n",
    "\n",
    "df20.to_csv('2021_batting_proj_1619_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct list of all XGBoost regression models\n",
    "all_models = [pa_model, ab_model, r_model, hr_model, rbi_model, sb_model, cs_model, avg_model, obp_model, ops_model, dol_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shapsum(X, i):\n",
    "    \"\"\"Function to display and save SHAP summary plot.\"\"\"\n",
    "    explainer = shap.TreeExplainer(all_models[i])\n",
    "    shap_values = explainer.shap_values(X)\n",
    "    shap.summary_plot(shap_values, X, show=False)\n",
    "    plt.title('Top 20 Features and Their Impact on Model Output: '+stat_names[i])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('shap_'+stat_names[i]+'.png')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display and save SHAP summary plots for all regression models\n",
    "for i in range(len(all_models)):\n",
    "    shapsum(X, i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
